{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1188ff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk \n",
    "import heapq\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb3683",
   "metadata": {},
   "source": [
    "# OBTAINING THE IMPORTANCE OF EVERY PREPROCESSED SENTENCE(WEIGHT)\n",
    "  -VISWANADH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02155ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af7b4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text=\"Artificial intelligence is human like intelligence. It is the study of intelligent artificial agents. Science and engineering to produce intelligent machines. Solve problems and have intelligence. Related to intelligent behavior. Developing of reasoning machines. Learn from mistakes and successes. Artificial intelligence is related to reasoning in everyday situations.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78569aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial intelligence is human like intelligence. It is the study of intelligent artificial agents. Science and engineering to produce intelligent machines. Solve problems and have intelligence. Related to intelligent behavior. Developing of reasoning machines. Learn from mistakes and successes. Artificial intelligence is related to reasoning in everyday situations.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564a84c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d82b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53f327c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text=text.lower()\n",
    "    tokens=[]\n",
    "    for i in nltk.word_tokenize(text):\n",
    "        tokens.append(i)\n",
    "    tokens=[i for i in tokens if i not in string.punctuation and i not in stopwords]    \n",
    "    formatted_text=' '.join(i for i in tokens)\n",
    "    return formatted_text\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f03e84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artificial intelligence human like intelligence study intelligent artificial agents science engineering produce intelligent machines solve problems intelligence related intelligent behavior developing reasoning machines learn mistakes successes artificial intelligence related reasoning everyday situations'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad076fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sent_score(sentences,important_words):\n",
    "    for sentence in sentences:\n",
    "        print(\"\\n\"+sentence)\n",
    "        num=0\n",
    "        den=0\n",
    "        for word in nltk.word_tokenize(sentence):\n",
    "            den+=1\n",
    "            if word in important_words:\n",
    "                num+=1\n",
    "        print((num*num)/den)    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bf14505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text,top_n_words=5):\n",
    "    original_sentence=[sentence for sentence in nltk.sent_tokenize(text)]\n",
    "    formatted_sentence=[preprocess(sentence) for sentence in original_sentence]\n",
    "    words=[]\n",
    "    for i in formatted_sentence:\n",
    "        for j in i.split(' '):\n",
    "            words.append(j)\n",
    "    top_n=[]\n",
    "    freq=nltk.FreqDist(words)\n",
    "    freq_sorted=sorted(freq.items(),key=lambda x:x[1],reverse=True)\n",
    "    for i in range(top_n_words):\n",
    "        top_n.append(freq_sorted[i][0])\n",
    "    print(\"The important words are\")\n",
    "    for i in top_n:\n",
    "        print(i)\n",
    "    calc_sent_score(formatted_sentence,top_n)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08fa2eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The important words are\n",
      "intelligence\n",
      "artificial\n",
      "intelligent\n",
      "machines\n",
      "related\n",
      "\n",
      "artificial intelligence human like intelligence\n",
      "1.8\n",
      "\n",
      "study intelligent artificial agents\n",
      "1.0\n",
      "\n",
      "science engineering produce intelligent machines\n",
      "0.8\n",
      "\n",
      "solve problems intelligence\n",
      "0.3333333333333333\n",
      "\n",
      "related intelligent behavior\n",
      "1.3333333333333333\n",
      "\n",
      "developing reasoning machines\n",
      "0.3333333333333333\n",
      "\n",
      "learn mistakes successes\n",
      "0.0\n",
      "\n",
      "artificial intelligence related reasoning everyday situations\n",
      "1.5\n"
     ]
    }
   ],
   "source": [
    "summarize(original_text,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33053ed3",
   "metadata": {},
   "source": [
    "#  Similarity between sentences using sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dfede7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import sigmoid_kernel\n",
    "def sentence_similarity(*sentence):\n",
    "    res=[]\n",
    "    for i in sentence:\n",
    "        res.append(i.lower())\n",
    "    df1=pd.DataFrame({\"x\":[j for j in res]})\n",
    "    cv=CountVectorizer(stop_words='english')\n",
    "    nlp_matrix=cv.fit_transform(df1[\"x\"])\n",
    "    sig=sigmoid_kernel(nlp_matrix,nlp_matrix)\n",
    "    for k in range(0,len(sig)):\n",
    "        for m in range(0,len(sig[k])):\n",
    "            if k!=m:\n",
    "                print(\"The sig_score between\",k,\" \",m,\" sentence is \",sig[k][m])\n",
    "        \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6bdf8672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sig_score between 0   1  sentence is  0.9051482536448664\n",
      "The sig_score between 0   2  sentence is  0.8700616617426719\n",
      "The sig_score between 0   3  sentence is  0.9051482536448664\n",
      "The sig_score between 1   0  sentence is  0.9051482536448664\n",
      "The sig_score between 1   2  sentence is  0.8700616617426719\n",
      "The sig_score between 1   3  sentence is  0.9051482536448664\n",
      "The sig_score between 2   0  sentence is  0.8700616617426719\n",
      "The sig_score between 2   1  sentence is  0.8700616617426719\n",
      "The sig_score between 2   3  sentence is  0.8700616617426719\n",
      "The sig_score between 3   0  sentence is  0.9051482536448664\n",
      "The sig_score between 3   1  sentence is  0.9051482536448664\n",
      "The sig_score between 3   2  sentence is  0.8700616617426719\n"
     ]
    }
   ],
   "source": [
    "sentence_similarity(\"Hey this is artificial intelligence\",\"Hey this is artificial intelligence\",\"Hey this is not artificial\",\"Hey Artificial intelligence and cant you metrics random forst \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7217807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
